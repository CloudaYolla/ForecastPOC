{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating and Importing Related Time Series Data\n",
    "\n",
    "## Obtaining Your Data\n",
    "\n",
    "This will take off where you stopped regarding your target time series data. In this particular exmaple, one master file contained both the target and the related time series information. That may or may not be the case for your problem. The goal here is to produce a file that contains the following 2 required attributes:\n",
    "\n",
    "1. Timestamp - Must be of the same format and total range as the target-time series data, as well as slices of values into the dates for your forecast.\n",
    "1. Item_ID - Must exist for all the time stamps for each item in your time series dataset\n",
    "\n",
    "In addition to those attributes we are looking for variables that shift over time that are impactful in some way towards our desired goal of predicting traffic volumes.\n",
    "\n",
    "Again the data was already bundled together for us in this sample so we will skip obtaining it a second time but that is where you would start otherwise.\n",
    "\n",
    "With the data ready to go, skip the blank cell ( feel free to add to it if you need to manipulate your own data) and execute the cells to handle our imports and retrieving our stored values from the previous notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building The Related Time Series File\n",
    "\n",
    "The challenge here is to make sure that we leave absolutely 0 entries with NaN values or the service will throw an error when building a Predictor. This is because the values must be present in order for us to make assumptions about their impact overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-01-01 00:00:00\n",
      "2018-09-30 23:00:00\n"
     ]
    }
   ],
   "source": [
    "related_time_series_df = target_df.copy()\n",
    "related_time_series_df.dropna()\n",
    "related_time_series_df = full_df.join(related_time_series_df, how='outer')\n",
    "cols = related_time_series_df.columns.tolist()\n",
    "related_time_series_df[cols] = related_time_series_df[cols].replace('', np.nan).ffill()\n",
    "related_time_series_df = related_time_series_df.loc['2017-01-01':]\n",
    "print (related_time_series_df.index.min())\n",
    "print (related_time_series_df.index.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see now that the data covers the range of our target time series of 2017's entire year to the end of our known data about 2018. We have not yet defined a forecast horizon yet but it is important to note here that the related data needs to cover that time span. To spoil later work, the horizon for us is 480 hours or 20 days, plenty of time with 9 months of validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly on prepping the base set of the data we validate there are no blanks or NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [holiday, temp, rain_1h, snow_1h, clouds_all, weather_main, weather_description, traffic_volume]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_time_series_df[related_time_series_df.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the columns and decide what we should keep:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_main</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>traffic_volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-07 09:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>255.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Snow</td>\n",
       "      <td>light snow</td>\n",
       "      <td>5343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-11-13 05:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>268.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mist</td>\n",
       "      <td>mist</td>\n",
       "      <td>2844.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-06-09 13:00:00</th>\n",
       "      <td>None</td>\n",
       "      <td>293.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>light rain</td>\n",
       "      <td>4186.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    holiday    temp  rain_1h  snow_1h  clouds_all  \\\n",
       "2018-02-07 09:00:00    None  255.07      0.0      0.0         5.0   \n",
       "2017-11-13 05:00:00    None  268.68      0.0      0.0         1.0   \n",
       "2018-06-09 13:00:00    None  293.44      0.0      0.0        90.0   \n",
       "\n",
       "                    weather_main weather_description  traffic_volume  \n",
       "2018-02-07 09:00:00         Snow          light snow          5343.0  \n",
       "2017-11-13 05:00:00         Mist                mist          2844.0  \n",
       "2018-06-09 13:00:00         Rain          light rain          4186.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_time_series_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few things to note here:\n",
    "\n",
    "* Holidays are not needed given this date is in the US, we can just use the Holidays feature within Forecast: https://docs.aws.amazon.com/forecast/latest/dg/API_SupplementaryFeature.html\n",
    "* Weather description seems to have more variety\n",
    "* Traffic volume will be removed here. \n",
    "* We still need to add back the item_id field.\n",
    "\n",
    "This leaves us with the following schema:\n",
    "\n",
    "* `timestamp` - The Index\n",
    "* `temp` - float\n",
    "* `rain_1h` - float\n",
    "* `snow_1h` - float\n",
    "* `clouds_all` - float\n",
    "* `weather_description` - string\n",
    "* `item_ID` - string\n",
    "\n",
    "The cell below will build that file for us.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-01 00:00:00</th>\n",
       "      <td>269.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>broken clouds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 01:00:00</th>\n",
       "      <td>269.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 02:00:00</th>\n",
       "      <td>269.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 03:00:00</th>\n",
       "      <td>269.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>scattered clouds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-01 04:00:00</th>\n",
       "      <td>269.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       temp  rain_1h  snow_1h  clouds_all weather_description  \\\n",
       "2017-01-01 00:00:00  269.75      0.0      0.0        75.0       broken clouds   \n",
       "2017-01-01 01:00:00  269.95      0.0      0.0         1.0        sky is clear   \n",
       "2017-01-01 02:00:00  269.75      0.0      0.0         1.0        sky is clear   \n",
       "2017-01-01 03:00:00  269.65      0.0      0.0        40.0    scattered clouds   \n",
       "2017-01-01 04:00:00  269.48      0.0      0.0         1.0        sky is clear   \n",
       "\n",
       "                    item_ID  \n",
       "2017-01-01 00:00:00       1  \n",
       "2017-01-01 01:00:00       1  \n",
       "2017-01-01 02:00:00       1  \n",
       "2017-01-01 03:00:00       1  \n",
       "2017-01-01 04:00:00       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restrict the columns to timestamp, traffic_volume\n",
    "related_time_series_df = related_time_series_df[['temp', 'rain_1h', 'snow_1h', 'clouds_all', 'weather_description']]\n",
    "# Add in item_id\n",
    "related_time_series_df['item_ID'] = \"1\"\n",
    "# Validate the structure\n",
    "related_time_series_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it off as a file:\n",
    "related_time_series_filename = \"related_time_series.csv\"\n",
    "related_time_series_path = data_dir + \"/\" + related_time_series_filename\n",
    "related_time_series_df.to_csv(related_time_series_path, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Related Data to the DatasetGroup\n",
    "\n",
    "Next we are going to create a related-time-series dataset, then add it to our dataset group and finally import our information and validate that it looks good. We will also delete this dataset import after we are done so that the first models do not yet receive any extra info from the related data.\n",
    "\n",
    "You can of course to not delete and get started right away with related data informed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region)\n",
    "forecast = session.client(service_name='forecast')\n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload Related File\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(related_time_series_filename).upload_file(related_time_series_path)\n",
    "related_s3DataPath = \"s3://\"+bucket_name+\"/\"+related_time_series_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the schema of your dataset here. Make sure the order of columns matches the raw data files.\n",
    "related_schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"temperature\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "       {\n",
    "         \"AttributeName\":\"rain_1h\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "       {\n",
    "         \"AttributeName\":\"snow_1h\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "       {\n",
    "         \"AttributeName\":\"clouds_all\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "       {\n",
    "         \"AttributeName\":\"weather\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      }\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_DSN = datasetName + \"_related\"\n",
    "response=forecast.create_dataset(\n",
    "                    Domain=\"CUSTOM\",\n",
    "                    DatasetType='RELATED_TIME_SERIES',\n",
    "                    DatasetName=related_DSN,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    Schema = related_schema\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetArn': 'arn:aws:forecast:us-east-1:503254810580:dataset/forecast_poc_m865_ds_related',\n",
       " 'DatasetName': 'forecast_poc_m865_ds_related',\n",
       " 'Domain': 'CUSTOM',\n",
       " 'DatasetType': 'RELATED_TIME_SERIES',\n",
       " 'DataFrequency': 'H',\n",
       " 'Schema': {'Attributes': [{'AttributeName': 'timestamp',\n",
       "    'AttributeType': 'timestamp'},\n",
       "   {'AttributeName': 'temperature', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'rain_1h', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'snow_1h', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'clouds_all', 'AttributeType': 'float'},\n",
       "   {'AttributeName': 'weather', 'AttributeType': 'string'},\n",
       "   {'AttributeName': 'item_id', 'AttributeType': 'string'}]},\n",
       " 'EncryptionConfig': {},\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2020, 6, 2, 19, 58, 58, 513000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 6, 2, 19, 58, 58, 513000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': '52923eb2-92b1-4195-ab87-a95b2f4ec362',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 02 Jun 2020 19:58:59 GMT',\n",
       "   'x-amzn-requestid': '52923eb2-92b1-4195-ab87-a95b2f4ec362',\n",
       "   'content-length': '729',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_datasetArn = response['DatasetArn']\n",
    "forecast.describe_dataset(DatasetArn=related_datasetArn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetImportJobName = 'DSIMPORT_JOB_RELATEDPOC'\n",
    "related_ds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=related_datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":related_s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:forecast:us-east-1:503254810580:dataset-import-job/forecast_poc_m865_ds_related/DSIMPORT_JOB_RELATEDPOC\n"
     ]
    }
   ],
   "source": [
    "rel_ds_import_job_arn=related_ds_import_job_response['DatasetImportJobArn']\n",
    "print(rel_ds_import_job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will poll until the import process has completed, once that has been accomplished we can review the metrics and decide to delete the data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTIVE\n",
      "CPU times: user 3.99 ms, sys: 0 ns, total: 3.99 ms\n",
      "Wall time: 130 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "while True:\n",
    "    dataImportStatus = forecast.describe_dataset_import_job(DatasetImportJobArn=rel_ds_import_job_arn)['Status']\n",
    "    print(dataImportStatus)\n",
    "    if dataImportStatus != 'ACTIVE' and dataImportStatus != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Related Time Series Data\n",
    "\n",
    "First let us examine the dataframe that we provided to Forecast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 18620 entries, 2017-01-01 00:00:00 to 2018-09-30 23:00:00\n",
      "Data columns (total 6 columns):\n",
      "temp                   18620 non-null float64\n",
      "rain_1h                18620 non-null float64\n",
      "snow_1h                18620 non-null float64\n",
      "clouds_all             18620 non-null float64\n",
      "weather_description    18620 non-null object\n",
      "item_ID                18620 non-null object\n",
      "dtypes: float64(4), object(2)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "related_time_series_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>rain_1h</th>\n",
       "      <th>snow_1h</th>\n",
       "      <th>clouds_all</th>\n",
       "      <th>weather_description</th>\n",
       "      <th>item_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-17 22:00:00</th>\n",
       "      <td>286.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>heavy intensity rain</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-04-09 05:00:00</th>\n",
       "      <td>285.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>sky is clear</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-03-23 00:00:00</th>\n",
       "      <td>275.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>overcast clouds</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       temp  rain_1h  snow_1h  clouds_all  \\\n",
       "2017-05-17 22:00:00  286.95      0.0      0.0        90.0   \n",
       "2017-04-09 05:00:00  285.49      0.0      0.0         1.0   \n",
       "2017-03-23 00:00:00  275.71      0.0      0.0        90.0   \n",
       "\n",
       "                      weather_description item_ID  \n",
       "2017-05-17 22:00:00  heavy intensity rain       1  \n",
       "2017-04-09 05:00:00          sky is clear       1  \n",
       "2017-03-23 00:00:00       overcast clouds       1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_time_series_df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see 18,609 entries and not one is a NaN value! This is perfect. Now to double check what we imported:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DatasetImportJobName': 'DSIMPORT_JOB_RELATEDPOC',\n",
       " 'DatasetImportJobArn': 'arn:aws:forecast:us-east-1:503254810580:dataset-import-job/forecast_poc_m865_ds_related/DSIMPORT_JOB_RELATEDPOC',\n",
       " 'DatasetArn': 'arn:aws:forecast:us-east-1:503254810580:dataset/forecast_poc_m865_ds_related',\n",
       " 'TimestampFormat': 'yyyy-MM-dd hh:mm:ss',\n",
       " 'DataSource': {'S3Config': {'Path': 's3://aiml-forecastpoc-z42jv9eu/related_time_series.csv',\n",
       "   'RoleArn': 'arn:aws:iam::503254810580:role/ForecastRolePOC'}},\n",
       " 'FieldStatistics': {'clouds_all': {'Count': 18620,\n",
       "   'CountDistinct': 21,\n",
       "   'CountNull': 0,\n",
       "   'CountNan': 0,\n",
       "   'Min': '0.0',\n",
       "   'Max': '92.0',\n",
       "   'Avg': 48.040655209452204,\n",
       "   'Stddev': 39.55817146688199},\n",
       "  'item_id': {'Count': 18620, 'CountDistinct': 1, 'CountNull': 0},\n",
       "  'rain_1h': {'Count': 18620,\n",
       "   'CountDistinct': 87,\n",
       "   'CountNull': 0,\n",
       "   'CountNan': 0,\n",
       "   'Min': '0.0',\n",
       "   'Max': '10.6',\n",
       "   'Avg': 0.05198227712137487,\n",
       "   'Stddev': 0.41226673566101313},\n",
       "  'snow_1h': {'Count': 18620,\n",
       "   'CountDistinct': 1,\n",
       "   'CountNull': 0,\n",
       "   'CountNan': 0,\n",
       "   'Min': '0.0',\n",
       "   'Max': '0.0',\n",
       "   'Avg': 0.0,\n",
       "   'Stddev': 0.0},\n",
       "  'temperature': {'Count': 18620,\n",
       "   'CountDistinct': 3815,\n",
       "   'CountNull': 0,\n",
       "   'CountNan': 0,\n",
       "   'Min': '246.15',\n",
       "   'Max': '310.07',\n",
       "   'Avg': 282.04625461868955,\n",
       "   'Stddev': 12.550891495009596},\n",
       "  'timestamp': {'Count': 18620,\n",
       "   'CountDistinct': 15312,\n",
       "   'CountNull': 0,\n",
       "   'Min': '2017-01-01T00:00:00Z',\n",
       "   'Max': '2018-09-30T23:00:00Z'},\n",
       "  'weather': {'Count': 18620, 'CountDistinct': 33, 'CountNull': 0}},\n",
       " 'DataSize': 0.0009389687329530716,\n",
       " 'Status': 'ACTIVE',\n",
       " 'CreationTime': datetime.datetime(2020, 6, 2, 19, 59, 2, 638000, tzinfo=tzlocal()),\n",
       " 'LastModificationTime': datetime.datetime(2020, 6, 2, 20, 1, 25, 514000, tzinfo=tzlocal()),\n",
       " 'ResponseMetadata': {'RequestId': 'da048832-c36a-4a39-bf3d-a38b2aa723a7',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 02 Jun 2020 20:03:06 GMT',\n",
       "   'x-amzn-requestid': 'da048832-c36a-4a39-bf3d-a38b2aa723a7',\n",
       "   'content-length': '1917',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.describe_dataset_import_job(DatasetImportJobArn=rel_ds_import_job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fantastict! No NaNs or nulls and the entire dataset is ready to go. Once that is done you are ready to move forward building your models with Amazon Forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to update the dataset group to include the related dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '4efe1c1a-0a15-480d-a0a7-12ed62fd3b9f',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1',\n",
       "   'date': 'Tue, 02 Jun 2020 20:03:12 GMT',\n",
       "   'x-amzn-requestid': '4efe1c1a-0a15-480d-a0a7-12ed62fd3b9f',\n",
       "   'content-length': '2',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast.update_dataset_group(DatasetGroupArn=datasetGroupArn, DatasetArns=[target_datasetArn, related_datasetArn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you'd like to dis-associate this information from the dataset group so you can build your models without related data simply uncomment the cell below and execute it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forecast.delete_dataset_import_job(DatasetImportJobArn=rel_ds_import_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
